{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c635c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cb458",
   "metadata": {},
   "source": [
    "# Que 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9102d816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The figure contains a rectangle or square.\n"
     ]
    }
   ],
   "source": [
    "# Check if the polygon has exactly 4 vertices\n",
    "# If it detects a rectangle or square than it draw the detected rectangle or square on the original image\n",
    "# Display the centroid as a red circle.\n",
    "# Write perimeter and centroid on the image.\n",
    "\n",
    "def find_rectangle(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to create a binary mask for white regions\n",
    "    _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "        # Check if the polygon has 4 vertices (a rectangle or square)\n",
    "        if len(approx) == 4:\n",
    "            perimeter = cv2.arcLength(approx, True)\n",
    "            M = cv2.moments(approx)\n",
    "            if M[\"m00\"] != 0:\n",
    "                centroid_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "                centroid_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "            else:\n",
    "                centroid_x, centroid_y = 0, 0\n",
    "\n",
    "            cv2.drawContours(image, [approx], -1, (0, 255, 0), 2)\n",
    "            cv2.circle(image, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(image, f\"Perimeter: {perimeter:.2f}\", (10, 30), font, 0.5, (0, 0, 255), 2)\n",
    "            cv2.putText(image, f\"Centroid: ({centroid_x}, {centroid_y})\", (10, 60), font, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow(\"Rectangle or Square\", image)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "image_path = 'data/rect1.jpg'\n",
    "\n",
    "# Check if the figure contains a rectangle or square and display its parameters\n",
    "if find_rectangle(image_path):\n",
    "    print(\"The figure contains a rectangle or square.\")\n",
    "else:\n",
    "    print(\"No rectangle or square found in the figure.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ee570",
   "metadata": {},
   "source": [
    "# Que 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc52bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 2 has more darkness, likely a girl.\n"
     ]
    }
   ],
   "source": [
    "# This function takes an image and determine the amount of darkness found in that image\n",
    "# In this way it differentiates the two images whether the image is of a boy or a girl\n",
    "\n",
    "def calculate_darkness_density(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _,binary = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Calculate the darkness density (number of dark pixels)\n",
    "    darkness_density = np.sum(binary == 0) / np.prod(binary.shape)\n",
    "\n",
    "    return darkness_density\n",
    "\n",
    "image1_path = 'data/fig3.jpg'  \n",
    "image2_path = 'data/fig4.jpg' \n",
    "\n",
    "darkness_density1 = calculate_darkness_density(image1_path)\n",
    "darkness_density2 = calculate_darkness_density(image2_path)\n",
    "\n",
    "# Determine which image has more darkness (more hair)\n",
    "if darkness_density1 > darkness_density2:\n",
    "    print(\"Image 1 has more darkness, likely a girl.\")\n",
    "else:\n",
    "    print(\"Image 2 has more darkness, likely a girl.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d43f65",
   "metadata": {},
   "source": [
    "# Que 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4f3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes the both images and calculate the variance of both images.\n",
    "# On the basis of variance it differentiates the both images.\n",
    "# The image with lower variance is considered the Blurred Image.\n",
    "\n",
    "def is_blurred_image(original_image_path, blurred_image_path):\n",
    "    \n",
    "    original_image = cv2.imread(original_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    blurred_image = cv2.imread(blurred_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Calculate the variance of pixel values for both images\n",
    "    variance_original = np.var(original_image)\n",
    "    variance_blurred = np.var(blurred_image)\n",
    "\n",
    "    # Determine which image is blurred based on variance\n",
    "    if variance_blurred < variance_original:\n",
    "        return \"Blurred Image\", \"Original Image\"\n",
    "    else:\n",
    "        return \"Original Image\", \"Blurred Image\"\n",
    "\n",
    "original_image_path = 'data/fig5.jpg'\n",
    "blurred_image_path = 'data/fig5_blur.jpg'\n",
    "\n",
    "blurred_title, original_title = is_blurred_image(original_image_path, blurred_image_path)\n",
    "\n",
    "original_image = cv2.imread(original_image_path)\n",
    "blurred_image = cv2.imread(blurred_image_path)\n",
    "\n",
    "cv2.imshow(blurred_title, blurred_image)\n",
    "cv2.imshow(original_title, original_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52db4d21",
   "metadata": {},
   "source": [
    "# Que 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a73b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each region is highlighted \n",
    "# A loop iterates through the contours, calculating the area and centroid of each region\n",
    "# It than shows the centroid of each region on the boundry.\n",
    "\n",
    "def calculate_and_display_areas(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresholded = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i, contour in enumerate(contours, start=1):\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            centroid_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "            centroid_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        else:\n",
    "            centroid_x, centroid_y = 0, 0\n",
    "\n",
    "        cv2.putText(image, f\"Area {i}: {area:.2f} pixels\", (centroid_x - 50, centroid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        cv2.circle(image, (centroid_x, centroid_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow(\"Colored Bars with Areas\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "image_path = 'data/fig1.jpg'  \n",
    "calculate_and_display_areas(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d058204",
   "metadata": {},
   "source": [
    "# Que 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81996002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar Area Covered(%)\n",
      "Light Gray: 40%\n"
     ]
    }
   ],
   "source": [
    "# First defining color ranges for each bar\n",
    "# Check which color range the mean_color falls into\n",
    "# Define the coordinates for the red arrow\n",
    "# Calculate the area of red arrow\n",
    "# calculating the area of each region and storing in array\n",
    "# displaying the areas\n",
    "\n",
    "def classify_color(mean_color):\n",
    "    color_ranges = {\n",
    "        'Yellow': ((200, 200, 0), (255, 255, 100)),\n",
    "        'Light Gray': ((160, 160, 160), (190, 190, 190)),\n",
    "        'Gray': ((100, 100, 100), (140, 140, 140)),\n",
    "        'Dark Gray': ((50, 50, 50), (90, 90, 90))\n",
    "    }\n",
    "    \n",
    "    for color, (lower, upper) in color_ranges.items():\n",
    "        if np.all(mean_color >= lower) and np.all(mean_color <= upper):\n",
    "            return color\n",
    "\n",
    "    return 'Unknown'\n",
    "\n",
    "def calculate_percentage_area_covered(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresholded = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    arrow_roi = (200, 50, 300, 150)  # (x, y, width, height)\n",
    "\n",
    "    arrow_area = arrow_roi[2] * arrow_roi[3]\n",
    "    bar_areas_covered = {}\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        roi_x, roi_y, roi_w, roi_h = arrow_roi\n",
    "\n",
    "        x_intersection = max(0, min(x + w, roi_x + roi_w) - max(x, roi_x))\n",
    "        y_intersection = max(0, min(y + h, roi_y + roi_h) - max(y, roi_y))\n",
    "\n",
    "        intersection_area = x_intersection * y_intersection\n",
    "        percentage_covered = (intersection_area / arrow_area) * 100\n",
    "        mask = np.zeros_like(image, dtype=np.uint8)\n",
    "        cv2.drawContours(mask, [contour], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "        mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mean_color = cv2.mean(image, mask=mask_gray)[:3]\n",
    "        bar_color = classify_color(mean_color)\n",
    "        bar_areas_covered[bar_color] = percentage_covered\n",
    "\n",
    "    print(\"Bar Area Covered(%)\")\n",
    "    for color, percentage in bar_areas_covered.items():\n",
    "        print(f\"{color}: {percentage:.0f}%\")\n",
    "\n",
    "image_path = 'data/fig2.jpg'  \n",
    "calculate_percentage_area_covered(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4f86e",
   "metadata": {},
   "source": [
    "# Que 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4f9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a blank white canvas to draw each bone segment separately\n",
    "# Extract the bounding rectangle of the bone segment\n",
    "# Seperating each segment\n",
    "# Calculating the height and width\n",
    "# Marking the bone\n",
    "# Displaying the bone\n",
    "\n",
    "def segment_and_display_bones(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    canvas = np.zeros_like(image)\n",
    "    for i, contour in enumerate(contours, start=1):\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bone_segment = image[y:y+h, x:x+w]\n",
    "\n",
    "        max_width = w\n",
    "        max_height = h\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(bone_segment, f\"Max Width: {max_width}px\", (10, 30), font, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(bone_segment, f\"Max Height: {max_height}px\", (10, 70), font, 1, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imwrite(f\"bone_segment_{i}.png\", bone_segment)\n",
    "\n",
    "        cv2.imshow(f\"Bone Segment {i}\", bone_segment)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "image_path = 'data/finger-bones.jpg'  \n",
    "\n",
    "segment_and_display_bones(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
